{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "from py2neo import Node, Relationship\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph('http://localhost:7474', password='1234')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = 'imran khan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ['imran khan', 'nawaz sharif', 'bilawal bhutto', 'asif zardari',\n",
    "            'arif alvi', 'maryam nawaz', 'asif khosa', 'fawad chaudhry', 'fazal ur rehman',\n",
    "            'shehbaz sharif', 'qamar bajwa', 'altaf hussain', 'pervez musharraf',\n",
    "            'mustafa kamal', 'siraj ul haq', 'sheikh rasheed', 'pervez khattak', 'asad umar',\n",
    "            'murad ali shah', 'aitzaz ahsan', 'asif ghafoor', 'PTI', 'PMLN', 'PPP', 'JUI', 'MQM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'model/summary_' + keyword + '_10_topics.json'\n",
    "twitter_file = 'model/topic-tweets_' + keyword + '_10_topics.json'\n",
    "youtube_file = 'model/topic-videos_' + keyword + '_10_topics.json'\n",
    "\n",
    "with open(twitter_file) as json_file:\n",
    "    tweet_data = json.load(json_file)\n",
    "\n",
    "with open(youtube_file) as json_file:\n",
    "    yt_data = json.load(json_file)\n",
    "\n",
    "\n",
    "with open(file) as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "tweet_data = random.sample(tweet_data, 50)\n",
    "yt_data = random.sample(yt_data, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating summaries\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "\n",
    "    summary = Node(\"Story\", Topic=data[i]['topic']\n",
    "                         , Summary=data[i]['Summary']\n",
    "                         , Sentiment=data[i]['Sentiment']\n",
    "                         , Date=data[i]['Date'])\n",
    "\n",
    "    graph.create(summary)\n",
    "    \n",
    "    ###\n",
    "    \n",
    "    for entity in entities:\n",
    "        if entity in data[i]['Summary'].lower():\n",
    "            node = graph.evaluate('MATCH(e:Entity {name: \"' + entity + '\"}) RETURN e')\n",
    "            if not node:\n",
    "                node = graph.evaluate('CREATE(e:Entity {name: \"' + entity + '\"}) RETURN e')\n",
    "                \n",
    "            r = Relationship(node, \"HAS_STORY\", summary)\n",
    "            graph.create(r)\n",
    "            \n",
    "    ###\n",
    "    \n",
    "\n",
    "    # Creating tweets and videos belonging to that summary\n",
    "\n",
    "    for j in range(0, len(tweet_data)):\n",
    "        if tweet_data[j]['Topic'] == i:\n",
    "            \n",
    "            tweet_type = tweet_data[j]['Type']                \n",
    "                \n",
    "            tweet = Node(tweet_type, Created_time = tweet_data[j]['Created_time']\n",
    "                                , URL = tweet_data[j]['URL']\n",
    "                                , User_name = tweet_data[j]['User_name']\n",
    "                                , Twitter_handle = tweet_data[j]['Twitter_handle']\n",
    "                                , Description = tweet_data[j]['Description']\n",
    "                                , Retweet_count = tweet_data[j]['Retweet_count']\n",
    "                                , Favorite_count = tweet_data[j]['Favorite_count']\n",
    "                                , Sentiment = tweet_data[j]['Sentiment']\n",
    "                                , Topic = tweet_data[j]['Topic'])\n",
    "            \n",
    "            graph.create(tweet)\n",
    "\n",
    "            r = Relationship(summary, \"HAS_TWEET\", tweet)\n",
    "\n",
    "            graph.create(r)\n",
    "    \n",
    "    \n",
    "    for j in range(0, len(yt_data)):\n",
    "        if yt_data[j]['Topic'] == i:\n",
    "            video = Node(\"Video\", Published_date = yt_data[j]['Published_date']\n",
    "                                , Title = yt_data[j]['Title']\n",
    "                                , URL = yt_data[j]['URL']\n",
    "                                , Channel_id = yt_data[j]['Channel_id']\n",
    "                                , Topic = yt_data[j]['Topic'])\n",
    "\n",
    "            graph.create(video)\n",
    "\n",
    "            r = Relationship(summary, \"HAS_VIDEO\", video)\n",
    "\n",
    "            graph.create(r)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
